{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product\" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Practice: Softmax Classifer Using Sequential</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, you will use a single layer Softmax to classify handwritten digits from the MNIST database.</p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Makeup_Data\">Make up Data</a></li>\n",
    "    <li><a href=\"#Model\">Criterion function, Optimizer, and Train the Model</a></li>\n",
    "    <li><a href=\"#Result\">Analyze Results</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries we need for this lab\n",
    "\n",
    "# Using the following line code to install the torchvision library\n",
    "# !conda install -y torchvision\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following function to visualize data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display data\n",
    "\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the training dataset:\n",
      "  Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "# Create and print the training dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the validating dataset:\n",
      "  Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): ToTensor()\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "# Create and print the validating dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validating dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data type is long: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data element:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Print the type of the element\n",
    "\n",
    "print(\"Type of data element: \", train_dataset[0][1].type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the rectangular tensor corresponds to a number that represents a pixel intensity as demonstrated by the following image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.32_image_values.png\" width=\"550\" alt=\"MNIST elements\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the fourth label: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label:  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Print the label\n",
    "\n",
    "print(\"The label: \", train_dataset[3][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the the fourth sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image:  None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image\n",
    "\n",
    "print(\"The image: \", show_data(train_dataset[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see its a 1. Now, plot the third sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image\n",
    "\n",
    "show_data(train_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Softmax function requires vector inputs. If you see the vector shape, you'll note it's 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the first element in train_dataset\n",
    "\n",
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the tensor as shown in this image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2image_to_vector.gif\" width=\"550\" alt=\"Flattern Image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the tensor is now 784."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2Imagetovector2.png\" width=\"550\" alt=\"Flattern Image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the input size and output size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set input size and output size\n",
    "\n",
    "input_dim = 28 * 28\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Softmax Classifier by using Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Create a softmax classifier by using sequenital\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- \n",
    "model = nn.Sequential(nn.Linear(input_dim, output_dim))\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model\">Define the Softmax Classifier, Criterion function, Optimizer, and Train the Model</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the size of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4baafbf48427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the parameters\n",
    "\n",
    "print('W: ', list(model.parameters())[0].size())\n",
    "print('b: ', list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cover the model parameters for each class to a rectangular grid:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a>     <img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2paramaters_to_image.gif\" width = 550, align = \"center\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate, optimizer, criterion and data loader\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and determine validation accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "n_epochs = 10\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "N_test = len(validation_dataset)\n",
    "\n",
    "def train_model(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        correct = 0\n",
    "        \n",
    "        #perform a prediction on the validation  data  \n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = model(x_test.view(-1, 28 * 28))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / N_test\n",
    "        loss_list.append(loss.data)\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "train_model(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Result\">Analyze Results</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(loss_list, color = color)\n",
    "ax1.set_xlabel('epoch', color = color)\n",
    "ax1.set_ylabel('total loss', color = color)\n",
    "ax1.tick_params(axis = 'y', color = color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color = color)  \n",
    "ax2.plot( accuracy_list, color = color)\n",
    "ax2.tick_params(axis = 'y', color = color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first five misclassified samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the misclassified samples\n",
    "\n",
    "count = 0\n",
    "for x, y in validation_dataset:\n",
    "    z = model(x.reshape(-1, 28 * 28))\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    if yhat != y:\n",
    "        show_data((x, y))\n",
    "        plt.show()\n",
    "        print(\"yhat: \",yhat)\n",
    "        count += 1\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
